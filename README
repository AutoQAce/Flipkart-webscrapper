# Web Scraping Project

## Overview

This project is a web scraping application developed using Python, Flask, Selenium, and BeautifulSoup. It scrapes product reviews including the product name, customer name, rating, comment heading, and full comment. The data is stored in a MongoDB database. The application is containerized using Docker and hosted on Azure Function Apps, with continuous integration set up through Azure DevOps.

## Table of Contents

- [Features](#features)
- [Technologies Used](#technologies-used)
- [Setup and Installation](#setup-and-installation)
- [Usage](#usage)
- [Database](#database)
- [Deployment](#deployment)
- [Continuous Integration](#continuous-integration)
- [Contributing](#contributing)
- [License](#license)

## Features

- Scrapes product reviews from specified websites.
- Extracts product name, customer name, rating, comment heading, and full comment.
- Stores scraped data in a MongoDB database.
- Dockerized application for easy deployment.
- Hosted on Azure Function Apps for scalable and serverless deployment.
- Continuous integration and deployment setup using Azure DevOps.

## Technologies Used

- **Python**: Core programming language.
- **Flask**: Web framework used for creating the web application.
- **Selenium**: Used for automating web browser interaction.
- **BeautifulSoup**: Library used for parsing HTML and extracting data.
- **MongoDB**: NoSQL database used for storing scraped data.
- **Docker**: Used for containerizing the application.
- **Azure Container Registry**: Stores Docker images.
- **Azure Function Apps**: Hosting platform for the web application.
- **Azure DevOps**: CI/CD pipeline for automated builds and deployments.

## Setup and Installation

### Prerequisites

- Python 3.x
- Docker
- MongoDB
- Azure Account
- Azure CLI
- Azure DevOps Account

### Installation Steps

1. **Clone the repository**
    ```sh
    git clone https://github.com/AutoQAce/Flipkart-webscrapper.git
    cd Flipkar-webscrapper
    ```

2. **Set up a virtual environment and install dependencies**
    ```sh
    python3 -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

3. **Configure MongoDB**
    - Ensure MongoDB is running on your machine or configure the connection string in your environment variables.
    OR
    - Create the free MongoDB Database connection online by visting https://www.mongodb.com/ -> Sign In -> Deployment -> Database -> Create New Cluster.

4. **Run the application locally**
    ```sh
    flask run
    ```

## Usage

1. **Access the web application**
    - Once the Flask application is running, navigate to `http://localhost:5000` in your web browser.

2. **Scrape product reviews**
    - Use the web interface to input the URL of the product page you want to scrape.

3. **View scraped data**
    - The scraped data will be displayed on the web interface and stored in MongoDB.

## Database

- **MongoDB**: The application uses MongoDB to store the scraped data. The data schema includes:
    - Product Name
    - Customer Name
    - Rating
    - Comment Heading
    - Full Comment

## Deployment

### Docker

1. **Build the Docker image**
    ```sh
    docker build -t flipkartwebscrapper .
    ```

2. **Run the Docker container**
    ```sh
    docker run -d -p 5000:5000 flipkartwebscrapper
    ```

### Azure

1. **Push Docker image to Azure Container Registry**
    ```
      sh ./build_docker.sh
    ```

2. **Deploy to Azure Function App**
    - Follow the Azure portal instructions to create a Function App and deploy the Docker container from the Azure Container Registry.

## Continuous Integration

1. **Set up Azure DevOps pipeline**
    - Create a new pipeline in Azure DevOps and configure it to build and deploy the Docker container to Azure Function App.

2. **Configure CI/CD**
    - Set up triggers to automatically build and deploy the application on code commits and pull requests.
